{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "scrapping_starter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmarinere/NikeCampaign/blob/master/scrapping_starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjpspbVS1FiJ",
        "colab_type": "text"
      },
      "source": [
        "## Web scrapping using python\n",
        "\n",
        "#### References\n",
        "1. [Practical Introduction to Web Scraping in Python](https://realpython.com/python-web-scraping-practical-introduction/)\n",
        "2. [Web Scraping using Python](https://www.datacamp.com/community/tutorials/web-scraping-using-python)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LM17kyGR83O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b4a2443-25c7-4dc4-da82-90a6a19eb500"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "root_path = 'drive/My Drive/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONq8zoln1FiW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "088e351c-44bf-49e1-d595-48d90e53847b"
      },
      "source": [
        "import string\n",
        "from requests import get\n",
        "import numpy as np\n",
        "from requests.exceptions import RequestException\n",
        "from contextlib import closing\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import os, sys\n",
        "import re \n",
        "import tweepy\n",
        "from tweepy.streaming import StreamListener\n",
        "from tweepy import OAuthHandler\n",
        "from tweepy import Stream\n",
        "import logging\n",
        "import json\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "#sentiment analysis package\n",
        "!pip install textblob\n",
        "from textblob import TextBlob\n",
        "\n",
        "#general text pre-processor\n",
        "!pip install nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "#tweet pre-processor \n",
        "!pip install tweet-preprocessor\n",
        "import preprocessor as p\n",
        "\n",
        "logger = logging.getLogger()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.12.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.6/dist-packages (0.6.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-VJjqKU6U3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols=  ['created_at', 'source', 'original_text', 'lang',\n",
        "                    'favorite_count', 'retweet_count', 'original_author'\n",
        "                    ,'name', \"following\", 'followers',\n",
        "                    'hashtags', 'mention', 'place_coord_boundaries', 'location']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPZeUN6NeoSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TweetSearch():\n",
        "    '''\n",
        "    This is a basic class to search and download twitter data.\n",
        "    You can build up on it to extend the functionalities for more \n",
        "    sophisticated analysis\n",
        "    '''\n",
        "    def __init__(self, cols=None,auth=None):\n",
        "        if cols is None:\n",
        "            self.cols =  ['created_at', 'source', 'original_text', \n",
        "                     'lang',\n",
        "                    'favorite_count', 'retweet_count', 'original_author'\n",
        "                    ,'name', \"following\", 'followers',\n",
        "                    'hashtags', 'mention', 'place_coord_boundaries', 'location']\n",
        "        else:\n",
        "            self.cols = cols\n",
        "  \n",
        "            \n",
        "        if auth is None:\n",
        "            #Variables that contains the user credentials to access Twitter API \n",
        "            consumer_key = os.environ.get('TWITTER_API_KEY')\n",
        "            consumer_secret = os.environ.get('TWITTER_API_SECRET')\n",
        "            access_token = os.environ.get('TWITTER_ACCESS_TOKEN')\n",
        "            access_token_secret = os.environ.get('TWITTER_ACCESS_TOKEN_SECRET')\n",
        "\n",
        "\n",
        "            #This handles Twitter authetification and the connection to Twitter Streaming API\n",
        "            auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "            auth.set_access_token(access_token, access_token_secret)\n",
        "            \n",
        "\n",
        "        #            \n",
        "        self.auth = auth\n",
        "        self.api = tweepy.API(auth, wait_on_rate_limit=True,\n",
        "          wait_on_rate_limit_notify=True)            \n",
        "            \n",
        "\n",
        "   \n",
        "    def get_tweets(self, user, csvfile=None):\n",
        "        \n",
        "        \n",
        "        df = pd.DataFrame(columns=self.cols)\n",
        "        \n",
        "        if not csvfile is None:\n",
        "            #If the file exists, then read the existing data from the CSV file.\n",
        "            if os.path.exists(csvfile):\n",
        "                df = pd.read_csv(csvfile, header=0)\n",
        "            \n",
        "\n",
        "        #page attribute in tweepy.cursor and  for twitter users \n",
        "        for page in tweepy.Cursor(api.user_timeline, id=user, include_rts=False).pages(40):\n",
        "\n",
        "\n",
        "\n",
        "            for status in page:\n",
        "                \n",
        "                new_entry = []\n",
        "                status = status._json\n",
        "                \n",
        "               \n",
        "                new_entry += [status['created_at'],\n",
        "                              status['source'], status['text'],\n",
        "                              status['lang'],status['favorite_count'], \n",
        "                              status['retweet_count'], \n",
        "                              status['user']['screen_name'], status['user']['name'],\n",
        "                              status['user']['friends_count'], status['user']['followers_count']]\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "                hashtags = \", \".join([hashtag_item['text'] for hashtag_item in status['entities']['hashtags']])\n",
        "              \n",
        "                new_entry.append(hashtags) #append the hashtags\n",
        "\n",
        "                #\n",
        "                mentions = \", \".join([mention['screen_name'] for mention in status['entities']['user_mentions']])\n",
        "                new_entry.append(mentions) #append the user mentions\n",
        "\n",
        "                try:\n",
        "                    xyz = status['place']['bounding_box']['coordinates']\n",
        "                    coordinates = [coord for loc in xyz for coord in loc]\n",
        "                except TypeError:\n",
        "                    coordinates = None\n",
        "                #\n",
        "                new_entry.append(coordinates)\n",
        "\n",
        "                try:\n",
        "                    location = status['user']['location']\n",
        "                except TypeError:\n",
        "                    location = ''\n",
        "                #\n",
        "                new_entry.append(location)\n",
        "\n",
        "                #now append a row to the dataframe\n",
        "                single_tweet_df = pd.DataFrame([new_entry], columns=self.cols)\n",
        "                df = df.append(single_tweet_df, ignore_index=True)\n",
        "\n",
        "        if not csvfile is None:\n",
        "            #save it to file\n",
        "            df.to_csv(csvfile, columns=self.cols, index=False, encoding=\"utf-8\")\n",
        "            \n",
        "        return df"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqrQK3xE1Fib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%writefile ../pyscrap_url.py\n",
        "\n",
        "def simple_get(url):\n",
        "    \"\"\"\n",
        "    Attempts to get the content at `url` by making an HTTP GET request.\n",
        "    If the content-type of response is some kind of HTML/XML, return the\n",
        "    text content, otherwise return None.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with closing(get(url, stream=True)) as resp:\n",
        "            if is_good_response(resp):\n",
        "                return resp.content  #.encode(BeautifulSoup.original_encoding)\n",
        "            else:\n",
        "                return None\n",
        "\n",
        "    except RequestException as e:\n",
        "        log_error('Error during requests to {0} : {1}'.format(url, str(e)))\n",
        "        return None\n",
        "\n",
        "\n",
        "def is_good_response(resp):\n",
        "    \"\"\"\n",
        "    Returns True if the response seems to be HTML, False otherwise.\n",
        "    \"\"\"\n",
        "    content_type = resp.headers['Content-Type'].lower()\n",
        "    return (resp.status_code == 200 \n",
        "            and content_type is not None \n",
        "            and content_type.find('html') > -1)\n",
        "\n",
        "\n",
        "def log_error(e):\n",
        "    \"\"\"\n",
        "    It is always a good idea to log errors. \n",
        "    This function just prints them, but you can\n",
        "    make it do anything.\n",
        "    \"\"\"\n",
        "    print(e)\n",
        "    \n",
        "def get_elements(url, tag='',search={}, fname=None):\n",
        "    \"\"\"\n",
        "    Downloads a page specified by the url parameter\n",
        "    and returns a list of strings, one per tag element\n",
        "    \"\"\"\n",
        "    \n",
        "    if isinstance(url,str):\n",
        "        response = simple_get(url)\n",
        "    else:\n",
        "        #if already it is a loaded html page\n",
        "        response = url\n",
        "\n",
        "    if response is not None:\n",
        "        html = BeautifulSoup(response, 'html.parser')\n",
        "        \n",
        "        res = []\n",
        "        if tag:    \n",
        "            for li in html.select(tag):\n",
        "                for name in li.text.split('\\n'):\n",
        "                    if len(name) > 0:\n",
        "                        res.append(name.strip())\n",
        "                       \n",
        "                \n",
        "        if search:\n",
        "            soup = html            \n",
        "            \n",
        "            \n",
        "            r = ''\n",
        "            if 'find' in search.keys():\n",
        "                print('findaing',search['find'])\n",
        "                soup = soup.find(**search['find'])\n",
        "                r = soup\n",
        "\n",
        "                \n",
        "            if 'find_all' in search.keys():\n",
        "                print('findaing all of',search['find_all'])\n",
        "                r = soup.find_all(**search['find_all'])\n",
        "   \n",
        "            if r:\n",
        "                for x in list(r):\n",
        "                    if len(x) > 0:\n",
        "                        res.extend(x)\n",
        "            \n",
        "        return res\n",
        "\n",
        "    # Raise an exception if we failed to get any data from the url\n",
        "    raise Exception('Error retrieving contents at {}'.format(url))    \n",
        "    \n",
        "    \n",
        "if get_ipython().__class__.__name__ == '__main__':\n",
        "    fire(get_tag_elements)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlUgViF3Ljmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = get_elements('https://africafreak.com/100-most-influential-twitter-users-in-africa',tag='h2')\n",
        "#This is to confirm that we successfully pulled the data \n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SnQvDezhdc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This is the first step i took in extracting the dataframe,\n",
        "#i used a range of 100 since there were some lines that were not useful\n",
        "numbers = []\n",
        "for item in range(100):\n",
        "  #I splited here by \".\" since all the numbers ended with . i wanted to seperate it \n",
        "  number = res[item].split('.')\n",
        "  numbers.append(number)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA-HhrOHkubl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this extract just the first object after the spit which is the numbers\n",
        "index = []\n",
        "for char in numbers:\n",
        "  index.append(char[0])\n",
        "#This line helps to extract the name of each of them from the list\n",
        "names =[]\n",
        "for name in numbers:\n",
        "  #All the usernames started with a bracket so i splitted using that to\n",
        "  #divide the username and the full name \n",
        "  names.append(name[-1].split(\"(\"))\n",
        "fullname = []\n",
        "for name in names:\n",
        "  #Since the full names where together i focused on the first element and\n",
        "  #removed the spaces before and after using strip\n",
        "  fullname.append(name[0].strip())\n",
        "handle =[]\n",
        "for name in names:\n",
        "  #This helps to append the username and the \"-1\" helps to stop just before the \n",
        "  #last character\n",
        "  handle.append(name[-1][:-1])\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLqHmA-TV-YR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Here i zipped all the columns and created a dataframe\n",
        "df = pd.DataFrame(  list(zip(index, fullname, handle)), columns=['Number','Name', 'Handle'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFGmaeRYySjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This helps to sort the value according to number\n",
        "df[\"Number\"]= df.Number.astype(int)\n",
        "df.sort_values('Number', inplace=True)\n",
        "df.drop(columns='Number', inplace=True)\n",
        "#This resets the index\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbCfX3RGF689",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2ca4761d-0405-4104-b1f2-0d8125d7d793"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Handle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Trevor Noah</td>\n",
              "      <td>@Trevornoah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Gareth Cliff</td>\n",
              "      <td>@GarethCliff</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Zuma</td>\n",
              "      <td>@SAPresident</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>News24</td>\n",
              "      <td>@News24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Julius Sello Malema</td>\n",
              "      <td>@Julius_S_Malema</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Name            Handle\n",
              "99          Trevor Noah       @Trevornoah\n",
              "98         Gareth Cliff      @GarethCliff\n",
              "97                 Zuma      @SAPresident\n",
              "96               News24           @News24\n",
              "95  Julius Sello Malema  @Julius_S_Malema"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDdxGZQW1Fim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url= 'https://www.atlanticcouncil.org/blogs/africasource/african-leaders-respond-to-coronavirus-on-twitter/'"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpghvHNVPrcf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b2dc6ebb-2d7a-411f-af03-6286e4807050"
      },
      "source": [
        "response = simple_get(url)\n",
        "res = get_elements(response, search={'find_all':{'class_':'wp-block-embed__wrapper'}})\n",
        "pattern = \"@[a-zA-Z]+[0-9]*[/_*]*[a-zA-Z]*\"\n",
        "twitter_handle = re.findall(pattern, str(res))\n",
        "print(\"The total number of African leaders extracted\", len(twitter_handle))\n",
        "twitter_handle[:5]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "findaing all of {'class_': 'wp-block-embed__wrapper'}\n",
            "The total number of African leaders extracted 52\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@EswatiniGovern1',\n",
              " '@MalawiGovt',\n",
              " '@hagegeingob',\n",
              " '@FinanceSC',\n",
              " '@PresidencyZA']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzwJg9urxGiw",
        "colab_type": "text"
      },
      "source": [
        "### Twitter Scraping to find the follower counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drIB42K412oK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "followers_count = {}\n",
        "for count in range(len(handle)):\n",
        "  try:\n",
        "    user = api.get_user(handle[count])\n",
        "    followers_count[handle[count]]= user.followers_count\n",
        "  except Exception as e:\n",
        "    pass"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnOANzZ3yPOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Follower_count']= df['Handle'].map(followers_count)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnydDM5tNTPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.sort_values('Follower_count', inplace=True, ascending=False)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA_FXrY2bSpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSpi53bYAVja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "062e14ef-3185-41d4-e397-57dd9f94bafa"
      },
      "source": [
        "#I tried to check all the null values to confirm the problem\n",
        "dfnull = df[df.isna().any(axis=1)]\n",
        "print (dfnull)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                Name            Handle  Follower_count\n",
            "93       John Robbie    @702JohnRobbie             NaN\n",
            "94       The New Age      @The_New_Age             NaN\n",
            "95      Afrinnovator     @Afrinnovator             NaN\n",
            "96      drew hinshaw     @drewfhinshaw             NaN\n",
            "97       Karen Allen    @BBCKarenAllen             NaN\n",
            "98  Vanessa Raphaely  @hurricanevaness             NaN\n",
            "99         andBeyond  @andBeyondSafari             NaN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkOOOHz6_w9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#i dropped all rows for blocked account that is returned null value for follower count i also performed a twitter search to confirm this\n",
        "df.dropna(inplace=True)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDjUJ4pUQZBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_ten = df.head(10)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuEKRuY-WI6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " first_ten.to_csv (\"/content/drive/My Drive/Colab Notebooks/African_influencer.csv\", index = False, header=True)\n",
        "df.to_csv (\"/content/drive/My Drive/Colab Notebooks/African_influencer_all.csv\", index = False, header=True)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEKWcuT6Nvte",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "african_follower = {}\n",
        "new_one ={}\n",
        "fullname = []\n",
        "for count in range(len(twitter_handle)):\n",
        "  try:\n",
        "    user = api.get_user(twitter_handle[count])\n",
        "    african_follower[twitter_handle[count]]= user.followers_count\n",
        "    new_one[twitter_handle[count]]= user.name \n",
        "  except Exception:\n",
        "    pass"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3uWjQaFZNJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = pd.DataFrame(twitter_handle, columns=['Twitter Handle'])\n",
        "df2['Follower_count']= df2['Twitter Handle'].map(african_follower)\n",
        "df2[\"Name\"] = df2['Twitter Handle'].map(new_one)\n",
        "df2.sort_values('Follower_count', inplace=True, ascending=False)\n",
        "df2.drop_duplicates(inplace=True)\n",
        "#since Boris Johnson and WHO aren't African Leader we will go ahead and drop those rows\n",
        "df2.drop(df2.index[[0,2]], inplace=True)\n",
        "df2.reset_index(drop=True, inplace=True) "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNJod-tcTbt0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d09168d8-2975-4de2-dec4-db321230499a"
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Twitter Handle</th>\n",
              "      <th>Follower_count</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@MBuhari</td>\n",
              "      <td>3268716</td>\n",
              "      <td>Muhammadu Buhari</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@PaulKagame</td>\n",
              "      <td>1981672</td>\n",
              "      <td>Paul Kagame</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@KagutaMuseveni</td>\n",
              "      <td>1810390</td>\n",
              "      <td>Yoweri K Museveni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@PresidencyZA</td>\n",
              "      <td>1597602</td>\n",
              "      <td>Presidency | South Africa ðŸ‡¿ðŸ‡¦</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@NAkufoAddo</td>\n",
              "      <td>1505244</td>\n",
              "      <td>Nana Akufo-Addo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Twitter Handle  Follower_count                          Name\n",
              "0         @MBuhari         3268716              Muhammadu Buhari\n",
              "1      @PaulKagame         1981672                   Paul Kagame\n",
              "2  @KagutaMuseveni         1810390             Yoweri K Museveni\n",
              "3    @PresidencyZA         1597602  Presidency | South Africa ðŸ‡¿ðŸ‡¦\n",
              "4      @NAkufoAddo         1505244               Nana Akufo-Addo"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjNyYMZGgkH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topten_african_leader = df2.head(10)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9TC-BKscYs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topten_african_leader.to_csv(\"/content/drive/My Drive/Colab Notebooks/African_leaders.csv\", index = False, header=True)\n",
        "df2.to_csv(\"/content/drive/My Drive/Colab Notebooks/African_leaders.csv\", index = False, header=True)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWShqwYDVJUw",
        "colab_type": "text"
      },
      "source": [
        "### I wan't to start scraping the tweets using the twitter handles rows from the data gotten previously"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmYhP8wFvht0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#i created for appending the data gotten from tweepy\n",
        "df_final = pd.DataFrame(columns=cols)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2653ggnVGhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "influentials_africa = '/content/drive/My Drive/influentials_africa.json'\n",
        "ts = TweetSearch()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3SZdxdpp-9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for user in df['Handle']:\n",
        "  try:\n",
        "      df_infl = ts.get_tweets(user)\n",
        "      df_final = df_final.append(df_infl, ignore_index=True)\n",
        "      print(\"collecting data from\", user)\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB0VZXClIE0e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f777ee6-2573-4e4d-f202-43934b6ac4ea"
      },
      "source": [
        "print(f\"{len(df_final)} where gotten from twitter African Influencers\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45030 where gotten from twitter African Leaders\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drPIDAyHzEpE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final= pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/all_influenncers_tweets.csv\")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmcKPBZJ4PP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#i decided to append all the data gotten to this data frame \n",
        "df_infl_gov = pd.DataFrame(columns=cols)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTulMWML3Obq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for user in df2['Twitter Handle']:\n",
        "    try:\n",
        "      df_inf = ts.get_tweets(user)\n",
        "      df_infl_gov = df_infl_gov.append(df_inf, ignore_index=True)\n",
        "      print(\"collecting data from\", user)\n",
        "    except:\n",
        "      pass \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAJh19IYGIqv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f0a7eab-eaa2-4775-efda-20e6f575e04b"
      },
      "source": [
        "print(f\"{len(df_infl_gov)} where gotten from twitter African Leaders\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25835 where gotten from twitter African Leaders\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy12sZjP3SMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#i saved the first twitter result for African Influencer as csv to my Google Drive\n",
        "df_infl_gov.to_csv(\"/content/drive/My Drive/Colab Notebooks/all_government_tweets.csv\", index = False, header=True)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEhuRBYJv3R1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#I saved the results for African Leaders as csv in my google drive\n",
        "df_final.to_csv(\"/content/drive/My Drive/Colab Notebooks/all_influencers_tweets.csv\", index = False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}